{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T07:26:14.052403Z",
     "start_time": "2024-08-05T07:26:13.939864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, LabelEncoder, OneHotEncoder\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)\n",
    "import folium\n",
    "from folium.plugins import HeatMap, MousePosition\n",
    "import random\n",
    "# from branca.element import Template, MacroElement\n",
    "from geopy.distance import geodesic\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, BayesianRidge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error, mean_squared_log_error, make_scorer\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_rows', 290)\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)"
   ],
   "id": "aef301a7707d053",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T07:26:21.569250Z",
     "start_time": "2024-08-05T07:26:14.785332Z"
    }
   },
   "cell_type": "code",
   "source": "df_ = pd.read_csv('hemnet.csv')",
   "id": "929b1b4d5ecdb939",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T07:26:22.173598Z",
     "start_time": "2024-08-05T07:26:21.572262Z"
    }
   },
   "cell_type": "code",
   "source": "df = df_.copy()",
   "id": "826f300c50a4d256",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T07:26:22.521163Z",
     "start_time": "2024-08-05T07:26:22.179339Z"
    }
   },
   "cell_type": "code",
   "source": "df_ = pd.read_csv(\"properties.csv\")",
   "id": "a24ad78a2b85ebea",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "deneme = pd.read_csv(\"hemnet_last.csv\")\n",
    "deneme.head(100)"
   ],
   "id": "4a0d158d96766451",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 'sold_date' değişkenini tarih tipine çevir\n",
    "deneme['sold_date'] = pd.to_datetime(deneme['sold_date'])\n",
    "\n",
    "# 'sold_date' değişkeninden gün bilgilerini al ve yeni bir sütun olarak ekle\n",
    "deneme['day'] = deneme['sold_date'].dt.day\n",
    "deneme.head()"
   ],
   "id": "7000ca40c5731066",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "deneme.drop(columns = ['sold_date'], axis = 1, inplace = True)\n",
    "deneme.head()\n"
   ],
   "id": "30927b961f7d907c",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "deneme.rename(columns={'day': 'sold_date'}, inplace=True)\n",
    "deneme.head()"
   ],
   "id": "c6e9c036efe99bd0",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "translation_dict={\n",
    "'Villa':'House',\n",
    "'Lägenhet':'Apartment',\n",
    "'Tomt':'Plot',\n",
    "'Radhus':'Town house',\n",
    "'Parhus':'Terraced house',\n",
    "'Vinterbonatfritidshus':'Winterized holiday home',\n",
    "'Övrig':'Other',\n",
    "'Kedjehus':'Linked house',\n",
    "'Par-/kedje-/radhus':'Row/Terrace/Town house',\n",
    "'Fritidshus':'Holiday home',\n",
    "'Gårdutanjordbruk':'Farm without agriculture',\n",
    "'Gård/skog':'Farm/Forest',\n",
    "'Gårdmedjordbruk':'Farm with agriculture',\n",
    "'Fritidsboende':'Holiday accommodation',\n",
    "'Gårdmedskogsbruk':'Farm with forestry'\n",
    "}\n",
    "\n",
    "\n",
    "deneme['property_type_en']=deneme['property_type'].map(translation_dict)\n",
    "deneme=deneme.drop([\"property_type\"],axis=1)\n",
    "deneme.head()\n"
   ],
   "id": "fdd484ebbcf2dc",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "translation_dict={\n",
    "'Äganderätt':'Freehold',\n",
    "'Bostadsrätt':'Cooperative apartment',\n",
    "'Annat':'Other',\n",
    "'Andelsboende':'Cooperative housing',\n",
    "'Tomträtt':'Landlease',\n",
    "'Andelibostadsförening':'Share in housing association',\n",
    "'Informationsaknas':'Information missing',\n",
    "'Hyresrätt':'Rental'\n",
    "}\n",
    "\n",
    "#Çeviriyiuygula\n",
    "deneme['ownership_type_en']=deneme['ownership_type'].map(translation_dict)\n",
    "deneme=deneme.drop([\"ownership_type\"],axis=1)\n",
    "deneme.head()"
   ],
   "id": "96d7bc889853d75d",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T07:03:51.866957Z",
     "start_time": "2024-08-05T07:03:51.856416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "\n",
    "#Sütunadınıdeğiştirme\n",
    "deneme.rename(columns={'broker':'estate_agent',\n",
    "'property_type_en':'property_type',\n",
    "'ownership_type_en':'ownership_type'},inplace=True)\n",
    "deneme.head()"
   ],
   "id": "13ab5138cbf4d6e9",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "deneme['balcony'].head(100)\n",
    "# 'balcony' değişkenini çevir\n",
    "deneme['balcony'] = deneme['balcony'].map({'Ja': 'Yes', 'Nej': 'No'})\n",
    "\n",
    "print(deneme)"
   ],
   "id": "e4f4beba382b9201",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "deneme.to_csv('hemnet_last2.csv', index = False)\n",
   "id": "23b4f9499bee68c2",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "deneme2 = pd.read_csv(\"hemnet_last2.csv\")\n",
    "deneme2.head()"
   ],
   "id": "fc85a25ca016bd72",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Unix zaman damgasını datetime formatına çevirin\n",
    "df_['sold_at'] = pd.to_datetime(df_['sold_at'], unit='s')\n",
    "\n",
    "# Yıl, ay ve gün bileşenlerini çıkartın\n",
    "df_['sold_year'] = df_['sold_at'].dt.year\n",
    "df_['sold_month'] = df_['sold_at'].dt.month\n",
    "df_['sold_date'] = df_['sold_at'].dt.day\n",
    "df_.drop(columns = ['sold_at'], axis = 1, inplace = True)\n",
    "df_.head()"
   ],
   "id": "d350ef5ce52c2e43",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_.head()\n",
    "df_['construction_year'] = pd.to_datetime(df_['construction_date'], errors='coerce').dt.year\n",
    "df_.drop(columns=['construction_date'], axis=1, inplace=True)"
   ],
   "id": "32f9a533b7d0b85c",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_['build_year'] = pd.to_numeric(df_['build_year'], errors='coerce')\n",
    "df_['build_year'] =df_['build_year'].astype(int)\n",
    "df_['build_year'] = pd.to_datetime(df_['build_year'], format='%Y', errors='coerce')\n",
    "\n",
    "df = df_.copy()"
   ],
   "id": "9008d8a87d6d65d6",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.head()",
   "id": "ff71791fbacf205d",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# df.to_csv('hemnet2.csv', index = False)\n",
    "\n",
    "def check_df(dataframe: pd.DataFrame, head: int = 5, q1: float = 0.05, q2: float = 0.50, q3: float = 0.95, q4: float = 0.99):\n",
    "    \"\"\"\n",
    "    Display comprehensive information about the dataframe.\n",
    "\n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): The input dataframe to analyze.\n",
    "        head (int): Number of rows to display for head and tail. Default is 5.\n",
    "        q1 (float): First quantile value. Default is 0.05.\n",
    "        q2 (float): Second quantile value. Default is 0.50.\n",
    "        q3 (float): Third quantile value. Default is 0.95.\n",
    "        q4 (float): Fourth quantile value. Default is 0.99.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the input is not a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    if not isinstance(dataframe, pd.DataFrame):\n",
    "        raise ValueError(\"Input must be a pandas DataFrame\")\n",
    "\n",
    "    def print_section(title):\n",
    "        print(f\"\\n{'-' * 20} {title} {'-' * 20}\\n\")\n",
    "\n",
    "    print_section(\"Shape of the dataframe\")\n",
    "    print(f\"Rows: {dataframe.shape[0]}, Columns: {dataframe.shape[1]}\")\n",
    "\n",
    "    print_section(\"Data Types\")\n",
    "    print(dataframe.dtypes)\n",
    "\n",
    "    print_section(\"Head\")\n",
    "    print(dataframe.head(head))\n",
    "\n",
    "    print_section(\"Tail\")\n",
    "    print(dataframe.tail(head))\n",
    "\n",
    "    print_section(\"Missing Values\")\n",
    "    missing = dataframe.isnull().sum()\n",
    "    missing_pct = 100 * dataframe.isnull().sum() / len(dataframe)\n",
    "    missing_table = pd.concat([missing, missing_pct], axis=1, keys=['Total', 'Percent'])\n",
    "    print(missing_table[missing_table['Total'] > 0].sort_values('Total', ascending=False))\n",
    "\n",
    "    print_section(\"Descriptive Statistics\")\n",
    "    datetime_columns = dataframe.select_dtypes(include='datetime64[ns]').columns\n",
    "    desc = dataframe.drop(datetime_columns, axis = 1).describe([0, q1, q2, q3, q4, 1]).T\n",
    "    desc['range'] = desc['max'] - desc['min']\n",
    "    desc['coef_var'] = desc['std'] / desc['mean']\n",
    "    print(desc)\n",
    "\n",
    "    print_section(\"Skewness\")\n",
    "    skew = dataframe.select_dtypes(include='number').skew().sort_values(ascending=False)\n",
    "    print(skew)\n",
    "\n",
    "    print_section(\"Kurtosis\")\n",
    "    kurt = dataframe.select_dtypes(include='number').kurt().sort_values(ascending=False)\n",
    "    print(kurt)\n",
    "\n",
    "    print_section(\"Correlation Matrix\")\n",
    "    corr = dataframe.select_dtypes(include='number').corr()\n",
    "    print(corr)\n",
    "\n",
    "    print_section(\"Memory Usage\")\n",
    "    memory_usage = dataframe.memory_usage(deep=True)\n",
    "    total_memory = memory_usage.sum()\n",
    "    print(f\"Total Memory Usage: {total_memory / 1e6:.2f} MB\")\n",
    "    print(memory_usage)\n",
    "\n",
    "    print_section(\"Unique Values\")\n",
    "    for col in dataframe.columns:\n",
    "        n_unique = dataframe[col].nunique()\n",
    "        print(f\"{col}: {n_unique} unique values\")\n",
    "\n",
    "    print_section(\"Sample Data\")\n",
    "    print(dataframe.sample(min(5, len(dataframe))))\n",
    "\n",
    "check_df(df)"
   ],
   "id": "a28700bab3d5f891",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def grab_col_names(dataframe, cat_th=10, car_th=300):\n",
    "    \"\"\"\n",
    "    Grab column names based on their types and cardinality.\n",
    "\n",
    "    Parameters:\n",
    "    cat_th (int): Threshold for numerical columns to be considered categorical. Default is 10.\n",
    "    car_th (int): Threshold for categorical columns to be considered cardinal. Default is 20.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Lists of categorical columns, numerical columns, and cardinal columns.\n",
    "    \"\"\"\n",
    "    cat_cols = [col for col in dataframe.columns if str(dataframe[col].dtypes) in ['category', 'object', 'bool']]\n",
    "    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and dataframe[col].dtypes in ['int', 'float']]\n",
    "    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and str(dataframe[col].dtypes) in ['category', 'object']]\n",
    "    cat_cols = cat_cols + num_but_cat\n",
    "    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n",
    "    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes in ['int', 'float', 'int64', 'float64']]\n",
    "    num_cols = [col for col in num_cols if col not in cat_cols]\n",
    "    date_cols = [col for col in dataframe.columns if dataframe[col].dtypes == 'datetime64[ns]']\n",
    "\n",
    "    return cat_cols, num_cols, cat_but_car, date_cols\n",
    "\n",
    "cat_cols, num_cols, cat_but_car, date_cols = grab_col_names(df, cat_th = 10, car_th = 300)"
   ],
   "id": "f9a99b54980ae488",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def reporting_col_types(dataframe):\n",
    "    \"\"\"\n",
    "    Report the types of columns in the dataframe.\n",
    "    \"\"\"\n",
    "    cat_cols, num_cols, cat_but_car, date_cols = grab_col_names(dataframe, cat_th = 10, car_th = 300)\n",
    "    print(f\"Observations: {dataframe.shape[0]}\\n\")\n",
    "    print(f\"Variables: {dataframe.shape[1]}\\n\")\n",
    "    print(f'cat_cols: {len(cat_cols)}\\n')\n",
    "    print(f'num_cols: {len(num_cols)}\\n')\n",
    "    print(f'cat_but_car: {len(cat_but_car)}\\n')\n",
    "    print(f'date_cols: {len(date_cols)}\\n')\n",
    "    print(f'The categoric columns are: {cat_cols}\\n')\n",
    "    print(f'The numerical columns are: {num_cols}\\n')\n",
    "    print(f'The categorical but cardinal columns are: {cat_but_car}\\n')\n",
    "    print(f'The date columns are: {date_cols}\\n')\n",
    "\n",
    "reporting_col_types(df)"
   ],
   "id": "f4730e012f006aa9",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def value_counts_ratio(df, columns, plot=False, verbose=False):\n",
    "    \"\"\"\n",
    "    Calculate the value counts and their proportions for specified columns in a DataFrame, and optionally plot pie charts and bar plots.\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The DataFrame to analyze.\n",
    "    - columns (list of str): List of column names to calculate value counts for.\n",
    "    - plot (bool): If True, plot pie charts and bar plots for each column. Default is False.\n",
    "    - verbose (bool): If True, print the value counts and percentages. Default is False.\n",
    "    Returns:\n",
    "    - value_counts_dfs (dict of pd.DataFrame): Dictionary of DataFrames containing value counts and percentages for each column.\n",
    "    \"\"\"\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise ValueError(\"Input must be a pandas DataFrame\")\n",
    "    if not all(isinstance(col, str) for col in columns):\n",
    "        raise ValueError(\"Columns must be a list of strings\")\n",
    "\n",
    "    value_counts_dfs = {}\n",
    "    for col in columns:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"Column '{col}' not found in DataFrame\")\n",
    "\n",
    "        value_counts_df = df[col].value_counts(normalize=True).to_frame().reset_index()\n",
    "        value_counts_df.columns = ['value', 'percentage']\n",
    "        value_counts_dfs[col] = value_counts_df\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"\\nColumn: {col}\")\n",
    "            print(value_counts_df)\n",
    "\n",
    "        if plot:\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "            fig.suptitle(f'{col.capitalize()} Proportions', fontsize=16)\n",
    "\n",
    "            def autopct_format(pct):\n",
    "                return f'{pct:.1f}%' if pct >= 2 else ''\n",
    "\n",
    "            wedges, texts, autotexts = ax1.pie(\n",
    "                value_counts_df['percentage'],\n",
    "                labels=None,\n",
    "                autopct=autopct_format,\n",
    "                colors=sns.color_palette(\"tab10\", len(value_counts_df)),\n",
    "                textprops={'fontsize': 10}\n",
    "            )\n",
    "            ax1.set_title('Pie Chart', fontsize=14)\n",
    "            ax1.legend(wedges, value_counts_df['value'], title=\"Values\", loc=\"center left\", bbox_to_anchor=(1, 0, 0.5, 1))\n",
    "\n",
    "            sns.barplot(x='value', y='percentage', data=value_counts_df, ax=ax2, palette=\"tab10\")\n",
    "            ax2.set_title('Bar Plot', fontsize=14)\n",
    "            ax2.set_xlabel('')\n",
    "            ax2.set_ylabel('Percentage')\n",
    "            ax2.set_xticklabels([])\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    return value_counts_dfs"
   ],
   "id": "f0625cd5f7f5f3b8",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "value_counts_ratio(df, ['property_type','housing_form', 'balcony', 'sold_year', 'sold_month', 'ownership_type'] ,plot = True)"
   ],
   "id": "7c1cda4088cd81e4",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "value_counts_dfs = value_counts_ratio(df, ['property_type','housing_form', 'balcony', 'sold_year', 'sold_month', 'ownership_type'])"
   ],
   "id": "9e68f4ad6ec7bab1",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "value_counts_dfs['ownership_type']"
   ],
   "id": "a9f414fc2624fd71",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "def null_dataframe(dataframe, plot=False, verbose=False):\n",
    "\n",
    "    \"\"\"\n",
    "    Analyze and visualize null values in a DataFrame.\n",
    "    Parameters:\n",
    "    - dataframe (pd.DataFrame): The DataFrame to analyze.\n",
    "    - cat_cols (list of str): List of categorical columns.\n",
    "    - num_cols (list of str): List of numerical columns.\n",
    "    - cat_but_car (list of str): List of categorical but cardinal columns.\n",
    "    - date_cols (list of str): List of date columns.\n",
    "    - plot (bool): Whether to plot charts for variables with null values. Default is False.\n",
    "    - verbose (bool): If True, print additional information. Default is False.\n",
    "    Returns:\n",
    "    - df_null (pd.DataFrame): DataFrame containing variables, their null value counts, and null ratios.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(dataframe, pd.DataFrame):\n",
    "        raise ValueError(\"Input must be a pandas DataFrame\")\n",
    "\n",
    "    df_null = dataframe.isnull().sum().sort_values(ascending=False).to_frame(name='null_values')\n",
    "    df_null.reset_index(inplace=True)\n",
    "    df_null.rename(columns={'index': 'variables'}, inplace=True)\n",
    "\n",
    "    variable_types = {col: 'Categorical' for col in cat_cols}\n",
    "    variable_types.update({col: 'Numerical' for col in num_cols})\n",
    "    variable_types.update({col: 'Categorical Cardinal' for col in cat_but_car})\n",
    "    variable_types.update({col: 'Date' for col in date_cols})\n",
    "\n",
    "    df_null['variable_type'] = df_null['variables'].map(variable_types)\n",
    "    df_null['null_ratio'] = df_null['null_values'] / len(dataframe)\n",
    "\n",
    "    null_variables = df_null[df_null['null_values'] != 0]['variables'].tolist()\n",
    "    notnull_variables = df_null[df_null['null_values'] == 0]['variables'].tolist()\n",
    "\n",
    "    if verbose:\n",
    "        print(f'The null variables are: {null_variables}\\n')\n",
    "        print(f'The not null variables are: {notnull_variables}\\n')\n",
    "        print(df_null)\n",
    "\n",
    "    if plot and null_variables:\n",
    "        for var in null_variables:\n",
    "            null_ratio = df_null[df_null['variables'] == var]['null_ratio'].values[0]\n",
    "\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "            fig.suptitle(f'Null Ratio for {var.capitalize()} Variable', fontsize=16)\n",
    "\n",
    "            def autopct_format(pct):\n",
    "                return f'{pct:.1f}%' if pct >= 2 else ''\n",
    "\n",
    "            wedges, texts, autotexts = ax1.pie(\n",
    "                [null_ratio, 1 - null_ratio],\n",
    "                labels=None,\n",
    "                autopct=autopct_format,\n",
    "                colors=['#636EFA', '#EF553B'],\n",
    "                textprops={'fontsize': 10}\n",
    "            )\n",
    "            ax1.set_title('Pie Chart', fontsize=14)\n",
    "            ax1.legend(wedges, ['Null', 'Not Null'], title=\"Values\", loc=\"center left\", bbox_to_anchor=(1, 0, 0.5, 1))\n",
    "\n",
    "            sns.barplot(x=['Null', 'Not Null'], y=[null_ratio, 1 - null_ratio], ax=ax2, palette=['#636EFA', '#EF553B'])\n",
    "            ax2.set_title('Bar Plot', fontsize=14)\n",
    "            ax2.set_xlabel('')\n",
    "            ax2.set_ylabel('Ratio')\n",
    "            ax2.set_xticklabels([])\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    return df_null"
   ],
   "id": "314e2c3aacef138f",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "null_dataframe(df, plot = True)"
   ],
   "id": "2acf76b14433688e",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "null_df  = null_dataframe(df)"
   ],
   "id": "58cb5268381ec0fc",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "null_df[:13]"
   ],
   "id": "9f4be230d35f74a3",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "num_cols"
   ],
   "id": "1562825691139043",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def zero_values_ratio(dataframe, plot=False, verbose=False):\n",
    "    \"\"\"\n",
    "    Analyze and visualize zero values in numerical columns of a DataFrame.\n",
    "    Parameters:\n",
    "    - dataframe (pd.DataFrame): The DataFrame to analyze.\n",
    "    - num_cols (list of str): List of numerical columns.\n",
    "    - plot (bool): Whether to plot charts for variables with zero values. Default is False.\n",
    "    - verbose (bool): If True, print additional information. Default is False.\n",
    "    Returns:\n",
    "    - zero_values_df (pd.DataFrame): DataFrame containing variables, their zero value counts, and zero ratios.\n",
    "    \"\"\"\n",
    "    zero_values_data = []\n",
    "\n",
    "    for col in num_cols:\n",
    "        zero_count = dataframe[dataframe[col] == 0].shape[0]\n",
    "        if zero_count != 0:\n",
    "            zero_ratio = zero_count / dataframe.shape[0]\n",
    "            zero_values_data.append({\n",
    "                'Variable': col,\n",
    "                'Zero_Count': zero_count,\n",
    "                'Zero_Ratio': zero_ratio\n",
    "            })\n",
    "\n",
    "            if verbose:\n",
    "                print(f'{col.capitalize()} column has {zero_count} zero values, ratio to all dataframe: {zero_ratio:.5f}')\n",
    "                print('\\n')\n",
    "\n",
    "            if plot:\n",
    "                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "                fig.suptitle(f'Zero Ratio for {col.capitalize()} Variable', fontsize=16)\n",
    "\n",
    "                def autopct_format(pct):\n",
    "                    return f'{pct:.1f}%' if pct >= 2 else ''\n",
    "\n",
    "                wedges, texts, autotexts = ax1.pie(\n",
    "                    [zero_ratio, 1 - zero_ratio],\n",
    "                    labels=None,\n",
    "                    autopct=autopct_format,\n",
    "                    colors=['#636EFA', '#EF553B'],\n",
    "                    textprops={'fontsize': 10}\n",
    "                )\n",
    "                ax1.set_title('Pie Chart', fontsize=14)\n",
    "                ax1.legend(wedges, ['Zero', 'Not Zero'], title=\"Values\", loc=\"center left\", bbox_to_anchor=(1, 0, 0.5, 1))\n",
    "\n",
    "                sns.barplot(x=['Zero', 'Not Zero'], y=[zero_ratio, 1 - zero_ratio], ax=ax2, palette=['#636EFA', '#EF553B'])\n",
    "                ax2.set_title('Bar Plot', fontsize=14)\n",
    "                ax2.set_xlabel('')\n",
    "                ax2.set_ylabel('Ratio')\n",
    "                ax2.set_xticklabels([])\n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "            if verbose:\n",
    "                print('\\n')\n",
    "\n",
    "    zero_values_df = pd.DataFrame(zero_values_data)\n",
    "\n",
    "    if verbose:\n",
    "        print(zero_values_df)\n",
    "\n",
    "    return zero_values_df"
   ],
   "id": "196f4cbcd51c2391",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "zero_values_ratio(df, plot = True)"
   ],
   "id": "a7b1a5947e920288",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "zero_values_df = zero_values_ratio(df)"
   ],
   "id": "c28c85b3d63e27f6",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "zero_values_df.sort_values('Zero_Count', ascending = False)"
   ],
   "id": "9460ad2471459271",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "df[df['latitude'] == 0]"
   ],
   "id": "3c701361c1e6cf6f",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "df[df['longitude'] == 0]"
   ],
   "id": "6133144539333c13",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "df = df[df['latitude'] != 0]"
   ],
   "id": "ea9c1ae0a1ccaa5b",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "df.iloc[208]"
   ],
   "id": "d28082c54fe0e542",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "df[df['living_area'] == 0]['housing_form'].value_counts()"
   ],
   "id": "3795da9ec83b26a4",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "df[df['living_area'] == 0]['housing_form'].value_counts()"
   ],
   "id": "f69fba4ae95b993",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def replace_zeros_with_mean(dataframe, column, target):\n",
    "    mean_values = dataframe.groupby(column)[target].transform(lambda x: x.replace(0, x.mean()))\n",
    "    dataframe[target] = dataframe[target].where(dataframe[target] != 0, mean_values)\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "    return dataframe"
   ],
   "id": "e632d61117dcf129",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def replace_zeros_with_median(dataframe, column, target):\n",
    "    median_values = dataframe.groupby(column)[target].transform(lambda x: x.replace(0, x.median()))\n",
    "    dataframe[target] = dataframe[target].where(dataframe[target] != 0, median_values)\n",
    "\n",
    "    return dataframe"
   ],
   "id": "292f9dd5c8700837",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def replace_nulls(dataframe, column, target, method='median', verbose = False):\n",
    "    if column not in dataframe.columns or target not in dataframe.columns:\n",
    "        raise ValueError(\"Specified column or target not found in dataframe.\")\n",
    "\n",
    "    if method == 'median':\n",
    "        replacement_values = dataframe.groupby(column)[target].transform('median')\n",
    "    elif method == 'mean':\n",
    "        replacement_values = dataframe.groupby(column)[target].transform('mean')\n",
    "    elif method == 'mode':\n",
    "        replacement_values = dataframe.groupby(column)[target].transform(lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid replacement method. Please choose 'median', 'mean', or 'mode'.\")\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Before filling nulls:\")\n",
    "        print(dataframe[target].isnull().sum())\n",
    "        print(\"Replacement values computed:\")\n",
    "        print(replacement_values)\n",
    "\n",
    "    dataframe[target] = dataframe[target].fillna(replacement_values)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"After filling nulls:\")\n",
    "        print(dataframe[target].isnull().sum())\n",
    "\n",
    "    return dataframe"
   ],
   "id": "886e55c8b37fb707",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "null_df = null_dataframe(df)"
   ],
   "id": "2659d787ee2c3c66",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "null_df"
   ],
   "id": "39d6f62724f3479b",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "zero_values_df = zero_values_ratio(df)"
   ],
   "id": "6a8f19826c45bdd1",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "zero_values_df"
   ],
   "id": "a26d18bd7a48f5f0",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "df[df['county'].isnull()]"
   ],
   "id": "c15154744f6ee3e6",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "df_coordinates_county = df.groupby('county')[['latitude', 'longitude']].mean().reset_index()\n",
    "df_coordinates_county[:20]"
   ],
   "id": "faee84e536be85fa",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "target_coords_1 = (59.31968, 18.06227)\n",
    "target_coords_2 = (59.23744, 18.12341)\n",
    "target_coords_3 = (59.44499, 13.43092)"
   ],
   "id": "2573f42d99c6043e",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "df_coordinates_county['distance1'] = df_coordinates_county.apply(lambda row: geodesic((row['latitude'], row['longitude']), target_coords_1).kilometers, axis = 1)\n",
    "df_coordinates_county['distance2'] = df_coordinates_county.apply(lambda row: geodesic((row['latitude'], row['longitude']), target_coords_2).kilometers, axis = 1)\n",
    "df_coordinates_county['distance3'] = df_coordinates_county.apply(lambda row: geodesic((row['latitude'], row['longitude']), target_coords_3).kilometers, axis = 1)"
   ],
   "id": "80e689ea3fdd1d9f",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "closest_county_1 = df_coordinates_county.loc[df_coordinates_county['distance1'].idxmin()]\n",
    "closest_county_2 = df_coordinates_county.loc[df_coordinates_county['distance2'].idxmin()]\n",
    "closest_county_3 = df_coordinates_county.loc[df_coordinates_county['distance3'].idxmin()]"
   ],
   "id": "d51a63c3830458e1",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "closest_county_1, closest_county_2, closest_county_3"
   ],
   "id": "4d61c2cd92f9f57a",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "df.loc[156981, 'county'] = 'Stockholms'\n",
    "df.loc[938636, 'county'] = 'Huddinge'\n",
    "df.loc[1084895, 'county'] = 'Karlstads'"
   ],
   "id": "e66a164f40de3a",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "df['street'].isnull().sum()"
   ],
   "id": "2a03ab14623be3b0",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "df['street'].value_counts()"
   ],
   "id": "df5a2330cef4287",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "df = replace_nulls(df, 'county', 'street', method = 'mode')\n",
    "# df = replace_nulls(df, 'county', 'price_change', method = 'median')\n",
    "df = replace_nulls(df, 'county', 'area', 'mode')\n",
    "df = replace_zeros_with_mean(df, 'housing_form', 'living_area')\n",
    "df = replace_zeros_with_mean(df, 'county', 'fee')\n",
    "df = replace_zeros_with_mean(df, 'county', 'wanted_price')\n",
    "df = replace_zeros_with_mean(df, 'housing_form', 'rooms')"
   ],
   "id": "428b14f7341fc14c",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "df[df['fee'] == 0]"
   ],
   "id": "77a2b2cf0ca478ed",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "df.loc[df['fee'] == 0, 'fee'] = df['fee'].median()"
   ],
   "id": "14785c953cd9d0f4",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "#df.to_csv('hemnet3.csv', index = False)\n",
    "\n",
    "def create_county_markers(lats, lons, counties, location=[62.0, 15.0], zoom_start=4):\n",
    "    \"\"\"\n",
    "    Create a map with circle markers for given counties and their coordinates.\n",
    "\n",
    "    Parameters:\n",
    "    - lats (list or pd.Series): List or Series of latitudes.\n",
    "    - lons (list or pd.Series): List or Series of longitudes.\n",
    "    - counties (list or pd.Series): List or Series of county names.\n",
    "    - location (list of float): Initial map center coordinates [latitude, longitude]. Default is [62.0, 15.0].\n",
    "    - zoom_start (int): Initial map zoom level. Default is 4.\n",
    "\n",
    "    Returns:\n",
    "    - sweden_map (folium.Map): Folium map object with the county markers.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(lats, (list, pd.Series)):\n",
    "        raise ValueError(\"Lats must be a list or a pandas Series\")\n",
    "    if not isinstance(lons, (list, pd.Series)):\n",
    "        raise ValueError(\"Lons must be a list or a pandas Series\")\n",
    "    if not isinstance(counties, (list, pd.Series)):\n",
    "        raise ValueError(\"Counties must be a list or a pandas Series\")\n",
    "    if len(lats) != len(lons) or len(lats) != len(counties):\n",
    "        raise ValueError(\"Lats, lons, and counties must have the same length\")\n",
    "\n",
    "    if isinstance(lats, pd.Series):\n",
    "        lats = lats.tolist()\n",
    "    if isinstance(lons, pd.Series):\n",
    "        lons = lons.tolist()\n",
    "    if isinstance(counties, pd.Series):\n",
    "        counties = counties.tolist()\n",
    "\n",
    "    sweden_map = folium.Map(location=location, zoom_start=zoom_start)\n",
    "\n",
    "    colors = ['red', 'blue', 'green', 'purple', 'orange', 'darkred', 'lightred', 'beige', 'darkblue',\n",
    "              'darkgreen', 'cadetblue', 'darkpurple', 'pink', 'lightblue', 'lightgreen', 'gray', 'black', 'lightgray']\n",
    "\n",
    "    for county, lat, lon in zip(counties, lats, lons):\n",
    "        color = random.choice(colors)\n",
    "        folium.CircleMarker(\n",
    "            location=[lat, lon],\n",
    "            radius=7,\n",
    "            popup=f\"County: {county},  Lat: {lat}, Lon: {lon}\",\n",
    "            color=color,\n",
    "            fill=True,\n",
    "            fillColor=color\n",
    "        ).add_to(sweden_map)\n",
    "    return sweden_map"
   ],
   "id": "55d1f915a637733f",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "sweden_map = create_county_markers(df_coordinates_county['latitude'], df_coordinates_county['longitude'], df_coordinates_county['county'])\n",
    "sweden_map.save('sweden_map.html')"
   ],
   "id": "c04b02cb8dae69ed",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "df_coordinates_county_price = df.groupby('county')[['latitude', 'longitude', 'price']].mean().sort_values('price', ascending=False).reset_index()\n",
    "df_coordinates_county_price[:20]"
   ],
   "id": "2d90d5acb2e59628",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def create_price_heatmap(dataframe):\n",
    "    \"\"\"\n",
    "    Create an interactive heatmap based on price values using given coordinates grouped by county.\n",
    "    Includes a mouse position display showing coordinates, markers for the top 3 most expensive counties,\n",
    "    and legends for both the markers and the heatmap colors.\n",
    "\n",
    "    Parameters:\n",
    "    - dataframe (pd.DataFrame): DataFrame containing 'county', 'latitude', 'longitude', and 'price' columns.\n",
    "\n",
    "    Returns:\n",
    "    - folium.Map: Folium map object with the heatmap, mouse position display, markers, and legends.\n",
    "    \"\"\"\n",
    "\n",
    "    if not all(col in dataframe.columns for col in ['county', 'latitude', 'longitude', 'price']):\n",
    "        raise ValueError(\"DataFrame must contain 'county', 'latitude', 'longitude', and 'price' columns\")\n",
    "\n",
    "    map_center = [dataframe['latitude'].mean(), dataframe['longitude'].mean()]\n",
    "    folium_map = folium.Map(location=map_center, zoom_start=6)\n",
    "\n",
    "    heat_data = dataframe[['latitude', 'longitude', 'price']].values.tolist()\n",
    "    HeatMap(heat_data).add_to(folium_map)\n",
    "\n",
    "    formatter = \"function(num) {return L.Util.formatNum(num, 5) + ' º ';};\"\n",
    "    mouse_position = MousePosition(\n",
    "        position='topright',\n",
    "        separator=' | ',\n",
    "        empty_string='NaN',\n",
    "        lng_first=True,\n",
    "        num_digits=20,\n",
    "        prefix=\"Coordinates:\",\n",
    "        lat_formatter=formatter,\n",
    "        lng_formatter=formatter\n",
    "    )\n",
    "    folium_map.add_child(mouse_position)\n",
    "\n",
    "    top_3_counties = dataframe.groupby('county')['price'].mean().nlargest(3).reset_index()\n",
    "\n",
    "    colors = ['red', 'darkred', 'orange']\n",
    "    for idx, row in top_3_counties.iterrows():\n",
    "        county_data = dataframe[dataframe['county'] == row['county']].iloc[0]\n",
    "        folium.Marker(\n",
    "            location=[county_data['latitude'], county_data['longitude']],\n",
    "            popup=f\"County: {row['county']}<br>Avg Price: ${row['price']:,.2f}\",\n",
    "            icon=folium.Icon(color=colors[idx], icon='star', prefix='fa')\n",
    "        ).add_to(folium_map)\n",
    "\n",
    "    legend_html = '''\n",
    "     <div style=\"\n",
    "     position: fixed;\n",
    "     bottom: 50px; left: 50px; width: 220px;\n",
    "     background-color: white; z-index:9999; font-size:14px;\n",
    "     border:2px solid grey; padding: 10px;\n",
    "     \">\n",
    "     <strong>Top 3 Most Expensive Counties</strong><br>\n",
    "     <i class=\"fa fa-star\" style=\"color: red;\"></i> 1st Most Expensive<br>\n",
    "     <i class=\"fa fa-star\" style=\"color: darkred;\"></i> 2nd Most Expensive<br>\n",
    "     <i class=\"fa fa-star\" style=\"color: orange;\"></i> 3rd Most Expensive<br>\n",
    "     <br>\n",
    "     <strong>Price Heatmap</strong><br>\n",
    "     <i style=\"background: rgba(255, 0, 0, 0.6); width: 18px; height: 18px; float: left; margin-right: 8px;\"></i> High<br>\n",
    "     <i style=\"background: rgba(255, 165, 0, 0.6); width: 18px; height: 18px; float: left; margin-right: 8px;\"></i> Medium<br>\n",
    "     <i style=\"background: rgba(0, 255, 0, 0.6); width: 18px; height: 18px; float: left; margin-right: 8px;\"></i> Low<br>\n",
    "     </div>\n",
    "     '''\n",
    "    folium_map.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "    return folium_map"
   ],
   "id": "208b8eccaa224264",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "heat_map = create_price_heatmap(df_coordinates_county_price)\n",
    "heat_map.save('heat_map.html')"
   ],
   "id": "425ffd3a1d51fb87",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def outlier_thresholds(dataframe, col_name, q1=0.25, q3=0.75):\n",
    "    quartile1 = dataframe[col_name].quantile(q1)\n",
    "    quartile3 = dataframe[col_name].quantile(q3)\n",
    "    interquantile_range = quartile3 - quartile1\n",
    "    up_limit = quartile3 + 1.5 * interquantile_range\n",
    "    low_limit = quartile1 - 1.5 * interquantile_range\n",
    "    return low_limit, up_limit"
   ],
   "id": "55f26270644b41cf",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def check_outlier(dataframe, col_name):\n",
    "    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n",
    "    if dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ],
   "id": "54afa155d8e46c5",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def remove_outlier(dataframe, col_name):\n",
    "    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n",
    "    df_without_outliers = dataframe[~((dataframe[col_name] < low_limit) | (dataframe[col_name] > up_limit))]\n",
    "    return df_without_outliers"
   ],
   "id": "8dbc81d13611409",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def replace_with_thresholds(dataframe, col):\n",
    "    low_limit, up_limit = outlier_thresholds(dataframe, col)\n",
    "    dataframe[col] = dataframe[col].apply(lambda x: low_limit if x < low_limit else (up_limit if x > up_limit else x))\n",
    "    return dataframe"
   ],
   "id": "2b90c374744c4e9",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def outlier_thresholds_per_categoric(dataframe, col_name, cat_name, q1=0.25, q3=0.75):\n",
    "    outlier_data = []\n",
    "    for cat in dataframe[cat_name].unique():\n",
    "        filtered_df = dataframe[dataframe[cat_name] == cat]\n",
    "        total_length = filtered_df.shape[0]\n",
    "        low_limit, up_limit = outlier_thresholds(filtered_df, col_name, q1=q1, q3=q3)\n",
    "\n",
    "        low_limit_length = filtered_df[filtered_df[col_name] < low_limit].shape[0]\n",
    "        up_limit_length = filtered_df[filtered_df[col_name] > up_limit].shape[0]\n",
    "\n",
    "        low_limit_ratio = low_limit_length / total_length\n",
    "        up_limit_ratio = up_limit_length / total_length\n",
    "\n",
    "        outlier_data.append((cat, low_limit, up_limit, low_limit_length, up_limit_length,\n",
    "                             low_limit_ratio, up_limit_ratio))\n",
    "\n",
    "    outlier_df = pd.DataFrame(outlier_data, columns=[cat_name, 'Low Limit', 'Up Limit',\n",
    "                                                     'Low Limit Length', 'Up Limit Length',\n",
    "                                                     'Low Limit Ratio', 'Up Limit Ratio'])\n",
    "\n",
    "    outlier_df['Low Limit'] = outlier_df['Low Limit'].map('{:.3f}'.format)\n",
    "    outlier_df['Up Limit'] = outlier_df['Up Limit'].map('{:.3f}'.format)\n",
    "    outlier_df['Low Limit Ratio'] = outlier_df['Low Limit Ratio'].map('{:.3f}'.format)\n",
    "    outlier_df['Up Limit Ratio'] = outlier_df['Up Limit Ratio'].map('{:.3f}'.format)\n",
    "\n",
    "    return outlier_df"
   ],
   "id": "fd56a73468d5b5ee",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df['price_change'] = pd.to_numeric(df['price_change'], errors='coerce')\n",
   "id": "366f7cf5de726b8",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "outlier_df_per_county_price_change = outlier_thresholds_per_categoric(df, 'price_change', 'county')"
   ],
   "id": "588eddfd9b0b4bab",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "outlier_df_per_county_price_change.sort_values(by = 'Up Limit Ratio', ascending = False)[:20]"
   ],
   "id": "154eedca921edb99",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "outlier_df_per_county_fee = outlier_thresholds_per_categoric(df, 'fee', 'county')"
   ],
   "id": "7d036cd4039d2ad0",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "outlier_df_per_county_fee.sort_values(by = 'Up Limit Ratio', ascending = False)[:20]"
   ],
   "id": "9be813165cac07cd",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "translation_dict = {\n",
    "    'Villa': 'House',\n",
    "    'Lägenhet': 'Apartment',\n",
    "    'Tomt': 'Plot',\n",
    "    'Radhus': 'Townhouse',\n",
    "    'Parhus': 'Terraced house',\n",
    "    'Vinterbonat fritidshus': 'Winterized holiday home',\n",
    "    'Övrig': 'Other',\n",
    "    'Kedjehus': 'Linked house',\n",
    "    'Par-/kedje-/radhus': 'Row/Terrace/Townhouse',\n",
    "    'Fritidshus': 'Holiday home',\n",
    "    'Gård utan jordbruk': 'Farm without agriculture',\n",
    "    'Gård/skog' : 'Farm/Forest',\n",
    "    'Gård med jordbruk' : 'Farm with agriculture',\n",
    "    'Fritidsboende': 'Holiday accommodation',\n",
    "    'Gård med skogsbruk': 'Farm with forestry'\n",
    "}\n",
    "\n",
    "\n",
    "df['property_type_en'] = df['property_type'].map(translation_dict)\n",
    "df= df.drop([\"property_type\"], axis=1)\n",
    "df.head()"
   ],
   "id": "24eebe48bda75758",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "translation_dict = {\n",
    "    'Äganderätt': 'Freehold',\n",
    "    'Bostadsrätt': 'Cooperative apartment',\n",
    "    'Annat': 'Other',\n",
    "    'Andelsboende': 'Cooperative housing',\n",
    "    'Tomträtt': 'Land lease',\n",
    "    'Andel i bostadsförening': 'Share in housing association',\n",
    "    'Information saknas': 'Information missing',\n",
    "    'Hyresrätt': 'Rental'\n",
    "}\n",
    "\n",
    "# Çeviriyi uygula\n",
    "df['ownership_type_en'] = df['ownership_type'].map(translation_dict)\n",
    "df= df.drop([\"ownership_type\"], axis=1)\n",
    "df.head()"
   ],
   "id": "a5f7b0c40a76eb77",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Sütun adını değiştirme\n",
    "df.rename(columns={'broker': 'estate_agent',\n",
    "                   'property_type_en': 'property_type',\n",
    "                   'ownership_type_en': 'ownership_type'}, inplace=True)\n",
    "df.head()"
   ],
   "id": "6157a9c7a173ecab",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def translate_story(story):\n",
    "    if isinstance(story, str):  # Sadece string değerleri işle\n",
    "        # Kat ve kat sayısı için dönüşüm\n",
    "        if ' av ' in story:\n",
    "            parts = story.split(', ')\n",
    "            for part in parts:\n",
    "                if ' av ' in part:\n",
    "                    floor_info = part.split(' av ')\n",
    "                    if len(floor_info) == 2:\n",
    "                        floor = floor_info[0].strip()\n",
    "                        total_floors = floor_info[1].strip()\n",
    "                        translated_part = f'{floor}th floor of {total_floors}'\n",
    "                        story = story.replace(part, translated_part)\n",
    "    # Asansör durumu için dönüşüm\n",
    "    if 'hiss finns ej' in story:\n",
    "        story = story.replace('hiss finns ej', 'no elevator')\n",
    "    elif 'hiss finns' in story:\n",
    "        story = story.replace('hiss finns', 'elevator available')\n",
    "\n",
    "    return story"
   ],
   "id": "bf7e4926368206c4",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# NaN değerlerini kontrol etmek ve apply fonksiyonunu güvenli kullanmak için fillna ile NaN değerlerini dolduruyoruz.\n",
    "df['story'].fillna('', inplace=True)\n",
    "# story sütununu çevir\n",
    "df['story'] = df['story'].apply(translate_story)\n",
    "df.head()"
   ],
   "id": "a2222f944424ce5b",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df['story'].fillna('unknown', inplace=True)\n",
    "df['story'].isnull().sum()"
   ],
   "id": "411399621f2319c5",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df['story'].isnull().sum()\n",
    "df['balcony'].fillna('no info', inplace=True)\n",
    "df['balcony'].isnull().sum()\n"
   ],
   "id": "a69966eb12b53222",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df= df.drop([\"floor\"], axis=1)\n",
    "df.head()"
   ],
   "id": "f4859f09cd317778",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 'balcony' değişkenini çevir\n",
    "df['balcony'] = df['balcony'].map({'Ja': 'Yes', 'Nej': 'No'})\n",
    "df['balcony']"
   ],
   "id": "78e6db07ce3066fe",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.to_csv('hemnet.csv', index = False)",
   "id": "e9c8c1cf2f4317f3",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_ = pd.read_csv(\"hemnet.csv\")\n",
    "df = df_.copy()\n",
    "df.head()"
   ],
   "id": "5f60a551fa91003b",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df['construction_year'] =df['construction_year'].astype(int)\n",
   "id": "a1e4128f3ab246f5",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cat_cols, num_cols, cat_but_car, date_cols = grab_col_names(df, cat_th = 10, car_th = 300)\n",
    "cat_cols"
   ],
   "id": "abc2446587e9dd42",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "num_cols",
   "id": "1d629081a64e485a",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.head()\n",
   "id": "e69773d9cb478114",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "one_hot_columns = ['property_type', 'housing_form', 'ownership_type', 'county','balcony']\n",
    "drop_columns = ['street', 'build_year', 'land_area', 'area', 'latitude', 'longitude', 'operating_cost',\n",
    "                 'association', 'estate_agent', 'story' ,'fee','url',\n",
    "                    'sold_date','sold_year', 'sold_month','price_change','construction_year','living_area']"
   ],
   "id": "d0b3ca3e2a75c700",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dfd = pd.get_dummies(df, columns = one_hot_columns, dtype = int, drop_first = True)\n",
    "dfd.head()"
   ],
   "id": "7550a5c23b8807af",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dfd['price'] = dfd['price'] / 100000\n",
    "dfd['wanted_price'] = dfd['wanted_price'] / 100000\n",
    "dfd['fee'] = dfd['fee'] / 100000\n",
    "\n",
    "dfd.drop(columns = drop_columns, inplace = True)"
   ],
   "id": "221144cb4bfc5fef",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "dfd.head()\n",
   "id": "578d33090149e0ad",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # price_change sütununun sayısal olup olmadığını kontrol etme ve NaN değerlerini temizleme\n",
    "# dfd['price_change'] = pd.to_numeric(dfd['price_change'], errors='coerce')"
   ],
   "id": "1a582b571a441f72",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# dfd = dfd.dropna(subset=['price_change'])\n",
    "# dfd.head()"
   ],
   "id": "84d6f763f779ed1d",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(df[['price_change', 'property_type']].isnull().sum())\n",
   "id": "ac58a1b7a71045da",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df = df.dropna(subset=['price_change', 'property_type'])\n",
   "id": "b033dd7f2505e202",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sns.boxplot(df, x = 'price_change', y = 'property_type')\n",
    "plt.xlim(0, 0.5)\n",
    "plt.show(block = True)"
   ],
   "id": "a49d294443f12b0c",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X = dfd.drop(columns = ['price'])\n",
    "y = dfd['price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=40)"
   ],
   "id": "755e69fe8e84f28e",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_pred = lr.predict(X_test)\n",
    "r2_lr = r2_score(y_test, lr_pred)\n",
    "mae_lr = mean_absolute_error(y_test, lr_pred)\n",
    "mse_lr = mean_squared_error(y_test, lr_pred)\n",
    "rmse_lr = mean_squared_error(y_test, lr_pred, squared = False)"
   ],
   "id": "6def5bcffab7ae69",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f'r2: {r2_lr:.4f}')\n",
    "print(f'mae: {mae_lr:.4f}')\n",
    "print(f'mse: {mse_lr:.4f}')\n",
    "print(f'rmse: {rmse_lr:.4f}')"
   ],
   "id": "5af0dc80d2da48ce",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ridge = Ridge()\n",
    "ridge.fit(X_train, y_train)\n",
    "ridge_pred = ridge.predict(X_test)\n",
    "r2_ridge = r2_score(y_test, ridge_pred)\n",
    "mae_ridge = mean_absolute_error(y_test, ridge_pred)\n",
    "mse_ridge = mean_squared_error(y_test, ridge_pred)\n",
    "rmse_ridge = mean_squared_error(y_test, ridge_pred, squared = False)"
   ],
   "id": "eab5c1cb02d15af5",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f'r2: {r2_ridge:.4f}')\n",
    "print(f'mae: {mae_ridge:.4f}')\n",
    "print(f'mse: {mse_ridge:.4f}')\n",
    "print(f'rmse: {rmse_ridge:.4f}')"
   ],
   "id": "7a39a6ef71f2af91",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "br = BayesianRidge()\n",
    "br.fit(X_train, y_train)\n",
    "br_pred = br.predict(X_test)\n",
    "r2_br = r2_score(y_test, br_pred)\n",
    "mea_br = mean_absolute_error(y_test, br_pred)\n",
    "mse_br = mean_squared_error(y_test, br_pred)\n",
    "rmse_br = mean_squared_error(y_test, br_pred, squared = False)"
   ],
   "id": "95e6f7aa3af7b766",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f'r2: {r2_br:.4f}')\n",
    "print(f'mae: {mea_br:.4f}')\n",
    "print(f'mse: {mse_br:.4f}')\n",
    "print(f'rmse: {rmse_br:.4f}')"
   ],
   "id": "76404e3c662eafee",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "en = ElasticNet()\n",
    "en.fit(X_train, y_train)\n",
    "en_pred = en.predict(X_test)\n",
    "r2_en = r2_score(y_test, en_pred)\n",
    "mae_en = mean_absolute_error(y_test, en_pred)\n",
    "mse_en = mean_squared_error(y_test, en_pred)\n",
    "rmse_en = mean_squared_error(y_test, en_pred, squared=False)"
   ],
   "id": "634f3a3b17688a78",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f'r2: {r2_en:.4f}')\n",
    "print(f'mae: {mae_en:.4f}')\n",
    "print(f'mse: {mse_en:.4f}')\n",
    "print(f'rmse: {rmse_en:.4f}')"
   ],
   "id": "cb11e38654f678dd",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "xgb = XGBRegressor(max_depth = 12, learning_rate = 0.15, reg_lambda = 10)\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_pred = xgb.predict(X_test)\n",
    "r2_xgb=r2_score(y_test,xgb_pred)\n",
    "mae_xgb=mean_absolute_error(y_test,xgb_pred)\n",
    "mse_xgb=mean_squared_error(y_test,xgb_pred)\n",
    "rmse_xgb=mean_squared_error(y_test,xgb_pred,squared=False)"
   ],
   "id": "c90416743393aa95",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f'r2: {r2_xgb:.4f}')\n",
    "print(f'mae: {mae_xgb:.4f}')\n",
    "print(f'mse: {mse_xgb:.4f}')\n",
    "print(f'rmse: {rmse_xgb:.4f}')"
   ],
   "id": "1341c83819436623",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "lgb = LGBMRegressor(n_estimators=200, random_state=40, learning_rate = 0.5, verbose = -1)\n",
    "lgb.fit(X_train, y_train)\n",
    "lgb_pred = lgb.predict(X_test)\n",
    "r2_lgb=r2_score(y_test,lgb_pred)\n",
    "mae_lgb=mean_absolute_error(y_test,lgb_pred)\n",
    "mse_lgb=mean_squared_error(y_test,lgb_pred)\n",
    "rmse_lgb=mean_squared_error(y_test,lgb_pred,squared=False)"
   ],
   "id": "6c867a7d37983385",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f'r2: {r2_lgb:.4f}')\n",
    "print(f'mae: {mae_lgb:.4f}')\n",
    "print(f'mse: {mse_lgb:.4f}')\n",
    "print(f'rmse: {rmse_lgb:.4f}')"
   ],
   "id": "813081e4243e7e0c",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "cb = CatBoostRegressor(verbose = False, depth = 9, loss_function='RMSE', iterations = 1200)\n",
    "cb.fit(X_train, y_train)\n",
    "cb_pred = cb.predict(X_test)\n",
    "r2_cb=r2_score(y_test,cb_pred)\n",
    "mae_cb=mean_absolute_error(y_test,cb_pred)\n",
    "mse_cb=mean_squared_error(y_test,cb_pred)\n",
    "rmse_cb=mean_squared_error(y_test,cb_pred,squared=False)"
   ],
   "id": "7d0d8b5442b95d51",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f'r2: {r2_cb:.4f}')\n",
    "print(f'mae: {mae_cb:.4f}')\n",
    "print(f'mse: {mse_cb:.4f}')\n",
    "print(f'rmse: {rmse_cb:.4f}')"
   ],
   "id": "564fe949b201bb92",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "lasso = Lasso()\n",
    "lasso.fit(X_train, y_train)\n",
    "lasso_pred = lasso.predict(X_test)\n",
    "r2_lasso=r2_score(y_test,lasso_pred)\n",
    "mae_lasso=mean_absolute_error(y_test,lasso_pred)\n",
    "mse_lasso=mean_squared_error(y_test,lasso_pred)\n",
    "rmse_lasso=mean_squared_error(y_test,lasso_pred,squared=False)"
   ],
   "id": "ae798da7d8279fb3",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f'r2: {r2_lasso:.4f}')\n",
    "print(f'mae: {mae_lasso:.4f}')\n",
    "print(f'mse: {mse_lasso:.4f}')\n",
    "print(f'rmse: {rmse_lasso:.4f}')"
   ],
   "id": "170f1629e851dc21",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "from sklearn.linear_model import GammaRegressor, PoissonRegressor, HuberRegressor\n",
    "hr = HuberRegressor()\n",
    "hr.fit(X_train, y_train) #runs very slowly\n",
    "hr_predict = hr.predict(X_test)\n",
    "r2_hr = r2_score(y_test, hr_predict)\n",
    "mae_hr = mean_absolute_error(y_test, hr_predict)\n",
    "mse_hr = mean_squared_error(y_test, hr_predict)\n",
    "rmse_hr = mean_squared_error(y_test, hr_predict, squared=False)"
   ],
   "id": "b7fcc74c49329e50",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f'r2: {r2_hr:.4f}')\n",
    "print(f'mae: {mae_hr:.4f}')\n",
    "print(f'mse: {mse_hr:.4f}')\n",
    "print(f'rmse: {rmse_hr:.4f}')"
   ],
   "id": "b2f76df393ecc4b3",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train) #runs very slowly\n",
    "gbr_pred = gbr.predict(X_test)\n",
    "r2_gbr = r2_score(y_test, gbr_pred)\n",
    "mae_gbr = mean_absolute_error(y_test, gbr_pred)\n",
    "mse_gbr = mean_squared_error(y_test, gbr_pred)\n",
    "rmse_gbr = mean_squared_error(y_test, gbr_pred, squared=False)"
   ],
   "id": "eea69f3baf962ed2",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f'r2: {r2_gbr:.4f}')\n",
    "print(f'mae: {mae_gbr:.4f}')\n",
    "print(f'mse: {mse_gbr:.4f}')\n",
    "print(f'rmse: {rmse_gbr:.4f}')"
   ],
   "id": "659f038fb685d52e",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "ab = AdaBoostRegressor()\n",
    "ab.fit(X_train, y_train) #runs very slowly\n",
    "ab_pred = ab.predict(X_test)\n",
    "r2_ab = r2_score(y_test, ab_pred)\n",
    "mae_ab = mean_absolute_error(y_test, ab_pred)\n",
    "mse_ab = mean_squared_error(y_test, ab_pred)\n",
    "rmse_ab = mean_squared_error(y_test, ab_pred, squared=False)"
   ],
   "id": "39ed26796eb04451",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f'r2: {r2_ab:.4f}')\n",
    "print(f'mae: {mae_ab:.4f}')\n",
    "print(f'mse: {mse_ab:.4f}')\n",
    "print(f'rmse: {rmse_ab:.4f}')\n"
   ],
   "id": "6615b73109ff7125",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e82531dcce252d38",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_ = pd.read_csv(\"hemnet.csv\")\n",
    "df = df_.copy()\n"
   ],
   "id": "9d2abe049cd95936",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler"
   ],
   "id": "1afcf5a5caf97467",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Kullanıcıdan veri alma (örnek)\n",
    "min_price = input(\"Aradığınız minimum fiyat: \")\n",
    "max_price = input(\"Aradığınız maksimum fiyat: \")\n",
    "user_county = input(\"Aradığınız şehir: \")\n",
    "property_type = input(\"Aradığınız mülk tipi: \")\n",
    "min_living_area = input(\"Aradığınız minimum yaşam alanı (m²): \")\n",
    "max_living_area = input(\"Aradığınız maksimum yaşam alanı (m²): \")\n",
    "min_rooms = input(\"Aradığınız minimum oda sayısı: \")\n",
    "max_rooms = input(\"Aradığınız maksimum oda sayısı: \")\n",
    "min_build_year = input(\"Aradığınız minimum yapım yılı: \")\n",
    "max_build_year = input(\"Aradığınız maksimum yapım yılı: \")\n",
    "user_balcony = input(\"Balkon tercihiniz (1 = Evet, 0 = Hayır, boş bırakın): \")\n"
   ],
   "id": "9ccf42dad2190726",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Kullanıcı profili\n",
    "user_profile = {\n",
    "    'min_price': float(min_price) if min_price else None,\n",
    "    'max_price': float(max_price) if max_price else None,\n",
    "    'county': user_county if user_county else None,\n",
    "    'property_type': property_type if property_type else None,\n",
    "    'min_living_area': float(min_living_area) if min_living_area else None,\n",
    "    'max_living_area': float(max_living_area) if max_living_area else None,\n",
    "    'min_rooms': int(min_rooms) if min_rooms else None,\n",
    "    'max_rooms': int(max_rooms) if max_rooms else None,\n",
    "    'min_build_year': int(min_build_year) if min_build_year else None,\n",
    "    'max_build_year': int(max_build_year) if max_build_year else None,\n",
    "    'balcony': int(user_balcony) if user_balcony else None\n",
    "}\n",
    "user_profile"
   ],
   "id": "25472a287dede64b",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Şehirleri sayısal değerlere dönüştürmek için bir sözlük oluşturun\n",
    "unique_counties = df['county'].unique()\n",
    "county_mapping = {county: idx for idx, county in enumerate(unique_counties)}\n"
   ],
   "id": "cf9bea267035c098",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Emlak verisini ve kullanıcı profilini dönüştürme\n",
    "df['county'] = df['county'].map(county_mapping)\n",
    "user_profile['county'] = county_mapping.get(user_profile['county'], -1) if user_profile['county'] else None\n"
   ],
   "id": "1b673cd4683676b6",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Veriyi ve kullanıcı profilini filtreleme\n",
    "filters = [\n",
    "    (df['price'] >= user_profile['min_price']) if user_profile['min_price'] else True,\n",
    "    (df['price'] <= user_profile['max_price']) if user_profile['max_price'] else True,\n",
    "    (df['rooms'] >= user_profile['min_rooms']) if user_profile['min_rooms'] else True,\n",
    "    (df['rooms'] <= user_profile['max_rooms']) if user_profile['max_rooms'] else True,\n",
    "    (df['build_year'] >= user_profile['min_build_year']) if user_profile['min_build_year'] else True,\n",
    "    (df['build_year'] <= user_profile['max_build_year']) if user_profile['max_build_year'] else True,\n",
    "    (df['balcony'] == user_profile['balcony']) if user_profile['balcony'] is not None else True,\n",
    "    (df['county'] == user_profile['county']) if user_profile['county'] is not None else True,\n",
    "    (df['property_type'] == user_profile['property_type']) if user_profile['property_type'] else True,\n",
    "    (df['living_area'] >= user_profile['min_living_area']) if user_profile['min_living_area'] else True,\n",
    "    (df['living_area'] <= user_profile['max_living_area']) if user_profile['max_living_area'] else True\n",
    "]\n",
    "filters\n"
   ],
   "id": "c29e9f55ab13c1e8",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "filtered_df = df.loc[filters[0]]\n",
    "for filter_condition in filters[1:]:\n",
    "    if not isinstance(filter_condition, bool):\n",
    "        filtered_df = filtered_df.loc[filter_condition]\n",
    "filtered_df.head()"
   ],
   "id": "6d7a6d919e7592c8",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Filtrelenmiş veri olup olmadığını kontrol etme\n",
    "if filtered_df.empty:\n",
    "    print(\"Belirtilen kriterlere uygun ev bulunamadı.\")\n",
    "else:\n",
    "    # Filtrelenmiş veriyi ve kullanıcı profilini standartlaştırma\n",
    "    features = filtered_df[['price', 'rooms', 'build_year', 'county', 'balcony', 'living_area']]\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "    # Kullanıcı profilini standartlaştırma\n",
    "    user_profile_values = [\n",
    "        user_profile['max_price'] if user_profile['max_price'] is not None else df['price'].max(),\n",
    "        user_profile['max_rooms'] if user_profile['max_rooms'] is not None else df['rooms'].max(),\n",
    "        user_profile['max_build_year'] if user_profile['max_build_year'] is not None else df['build_year'].max(),\n",
    "        user_profile['county'] if user_profile['county'] is not None else -1,\n",
    "        user_profile['balcony'] if user_profile['balcony'] is not None else df['balcony'].mode()[0],\n",
    "        user_profile['max_living_area'] if user_profile['max_living_area'] is not None else df['living_area'].max()\n",
    "    ]\n",
    "\n",
    "    user_profile_scaled = scaler.transform([user_profile_values])\n",
    "\n",
    "    # Benzerlik hesaplama\n",
    "    similarities = cosine_similarity(user_profile_scaled, scaled_features)\n",
    "    filtered_df['similarity'] = similarities[0]\n",
    "\n",
    "    # Öneri listesi\n",
    "    recommendations = filtered_df.sort_values(by='similarity', ascending=False)\n",
    "    print(\"Önerilen Evler:\")\n",
    "    print(recommendations[['street', 'price', 'rooms', 'build_year', 'balcony', 'living_area']])"
   ],
   "id": "2adf037a8980aac4",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f8cb94e4980ad6ca",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "44229569d7b9846",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Kullanıcıdan değerleri almak için bir fonksiyon\n",
    "def get_user_input():\n",
    "    property_type = input(\"Enter property type (Apartment/House): \").capitalize()\n",
    "    price_range = input(\"Enter price range (e.g., 2700000-3100000): \")\n",
    "    min_price, max_price = map(int, price_range.split('-'))\n",
    "    county = input(\"Enter county (e.g., Stockholms): \").capitalize()\n",
    "    \n",
    "    user_input = {\n",
    "        'property_type': property_type,\n",
    "        'min_price': min_price,\n",
    "        'max_price': max_price,\n",
    "        'county': county\n",
    "    }\n",
    "    \n",
    "    return user_input\n",
    "\n",
    "# Kullanıcıdan değerleri al\n",
    "user_input = get_user_input()\n",
    "\n",
    "# Kullanıcı girdilerine göre veri filtresi uygulama\n",
    "filtered_df = df[\n",
    "    (df['property_type'] == user_input['property_type']) &\n",
    "    (df['price'] >= user_input['min_price']) &\n",
    "    (df['price'] <= user_input['max_price']) &\n",
    "    (df['county'] == user_input['county'])\n",
    "]\n",
    "\n",
    "# Önerileri gösterme\n",
    "if not filtered_df.empty:\n",
    "    print(f\"Found {len(filtered_df)} matching properties:\")\n",
    "    for idx, row in filtered_df.iterrows():\n",
    "        print(f\"\\nStreet: {row['street']}\")\n",
    "        print(f\"Price: {row['price']}\")\n",
    "        print(f\"County: {row['county']}\")\n",
    "        print(f\"Living Area: {row['living_area']}\")\n",
    "        print(f\"Property Type: {row['property_type']}\")\n",
    "        print(f\"URL: {row['url']}\")\n",
    "else:\n",
    "    print(\"No matching properties found.\")"
   ],
   "id": "f74e4beb26c495fe",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f1d65926482ca5bc",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3acb58ba63e3c5c1",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Örnek emlak verisi\n",
    "data = {\n",
    "    'street': ['Östra Hamngatan 2', 'Läckövägen 26 *ACCEPTERAT PRIS*'],\n",
    "    'price': [2750000, 3650000],\n",
    "    'county': ['Västerås', 'Stockholms'],\n",
    "    'rooms': [2, 3],\n",
    "    'build_year': [2011, 1943],\n",
    "    'balcony': [1, 0]  # Evet = 1, Hayır = 0\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Kullanıcıdan veri alma (örnek)\n",
    "min_price = float(input(\"Aradığınız minimum fiyat: \"))\n",
    "max_price = float(input(\"Aradığınız maksimum fiyat: \"))\n",
    "user_county = input(\"Aradığınız şehir: \")\n",
    "min_rooms = int(input(\"Aradığınız minimum oda sayısı: \"))\n",
    "max_rooms = int(input(\"Aradığınız maksimum oda sayısı: \"))\n",
    "min_build_year = int(input(\"Aradığınız minimum yapım yılı: \"))\n",
    "max_build_year = int(input(\"Aradığınız maksimum yapım yılı: \"))\n",
    "user_balcony = int(input(\"Balkon tercihiniz (1 = Evet, 0 = Hayır): \"))\n",
    "\n",
    "# Kullanıcı profili\n",
    "user_profile = {\n",
    "    'min_price': min_price,\n",
    "    'max_price': max_price,\n",
    "    'county': user_county,\n",
    "    'min_rooms': min_rooms,\n",
    "    'max_rooms': max_rooms,\n",
    "    'min_build_year': min_build_year,\n",
    "    'max_build_year': max_build_year,\n",
    "    'balcony': user_balcony\n",
    "}\n",
    "\n",
    "# Şehirleri sayısal değerlere dönüştürmek için bir sözlük oluşturun\n",
    "unique_counties = df['county'].unique()\n",
    "county_mapping = {county: idx for idx, county in enumerate(unique_counties)}\n",
    "\n",
    "# Emlak verisini ve kullanıcı profilini dönüştürme\n",
    "df['county'] = df['county'].map(county_mapping)\n",
    "user_profile['county'] = county_mapping.get(user_profile['county'], -1)  # -1 veya başka bir değer geçerli değilse\n",
    "\n",
    "# Veriyi ve kullanıcı profilini filtreleme\n",
    "filtered_df = df[\n",
    "    (df['price'] >= user_profile['min_price']) &\n",
    "    (df['price'] <= user_profile['max_price']) &\n",
    "    (df['rooms'] >= user_profile['min_rooms']) &\n",
    "    (df['rooms'] <= user_profile['max_rooms']) &\n",
    "    (df['build_year'] >= user_profile['min_build_year']) &\n",
    "    (df['build_year'] <= user_profile['max_build_year']) &\n",
    "    (df['balcony'] == user_profile['balcony'])\n",
    "]\n",
    "\n",
    "# Filtrelenmiş veri olup olmadığını kontrol etme\n",
    "if filtered_df.empty:\n",
    "    print(\"Belirtilen kriterlere uygun ev bulunamadı.\")\n",
    "else:\n",
    "    # Filtrelenmiş veriyi ve kullanıcı profilini standartlaştırma\n",
    "    features = filtered_df[['price', 'rooms', 'build_year', 'county', 'balcony']]\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "    # Kullanıcı profilini standartlaştırma\n",
    "    user_profile_scaled = scaler.transform([[user_profile['max_price'], user_profile['max_rooms'], user_profile['max_build_year'], user_profile['county'], user_profile['balcony']]])\n",
    "\n",
    "    # Benzerlik hesaplama\n",
    "    similarities = cosine_similarity(user_profile_scaled, scaled_features)\n",
    "    filtered_df['similarity'] = similarities[0]\n",
    "\n",
    "    # Öneri listesi\n",
    "    recommendations = filtered_df.sort_values(by='similarity', ascending=False)\n",
    "    print(\"Önerilen Evler:\")\n",
    "    print(recommendations[['street', 'price', 'rooms', 'build_year', 'balcony']])\n"
   ],
   "id": "7d19d0dbae793788",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d2765dc5c4acfa87",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d2b612d7406ca5a4",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "cb85908da9820db4",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv(\"hemnet.csv\")\n",
    "# build_year sütununu yıl olarak parçalama\n",
    "df['build_year'] = pd.to_datetime(df['build_year']).dt.year\n",
    "df.head()"
   ],
   "id": "54911313f458d5c3",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Kullanıcıdan veri alma (örnek)\n",
    "min_price = input(\"Aradığınız minimum fiyat: \")\n",
    "max_price = input(\"Aradığınız maksimum fiyat: \")\n",
    "user_county = input(\"Aradığınız şehir: \")\n",
    "property_type = input(\"Aradığınız mülk tipi: \")\n",
    "min_living_area = input(\"Aradığınız minimum yaşam alanı (m²): \")\n",
    "max_living_area = input(\"Aradığınız maksimum yaşam alanı (m²): \")\n",
    "min_rooms = input(\"Aradığınız minimum oda sayısı: \")\n",
    "max_rooms = input(\"Aradığınız maksimum oda sayısı: \")\n",
    "min_build_year = input(\"Aradığınız minimum yapım yılı: \")\n",
    "max_build_year = input(\"Aradığınız maksimum yapım yılı: \")\n",
    "user_balcony = input(\"Balkon tercihiniz (1 = Evet, 0 = Hayır, boş bırakın): \")\n",
    "\n",
    "# Kullanıcı profili\n",
    "user_profile = {\n",
    "    'min_price': float(min_price) if min_price else None,\n",
    "    'max_price': float(max_price) if max_price else None,\n",
    "    'county': user_county if user_county else None,\n",
    "    'property_type': property_type if property_type else None,\n",
    "    'min_living_area': float(min_living_area) if min_living_area else None,\n",
    "    'max_living_area': float(max_living_area) if max_living_area else None,\n",
    "    'min_rooms': int(min_rooms) if min_rooms else None,\n",
    "    'max_rooms': int(max_rooms) if max_rooms else None,\n",
    "    'min_build_year': int(min_build_year) if min_build_year else None,\n",
    "    'max_build_year': int(max_build_year) if max_build_year else None,\n",
    "    'balcony': int(user_balcony) if user_balcony else None\n",
    "}\n",
    "\n",
    "# Şehirleri sayısal değerlere dönüştürmek için bir sözlük oluşturun\n",
    "unique_counties = df['county'].unique()\n",
    "county_mapping = {county: idx for idx, county in enumerate(unique_counties)}\n",
    "\n",
    "# Emlak verisini ve kullanıcı profilini dönüştürme\n",
    "df['county'] = df['county'].map(county_mapping)\n",
    "user_profile['county'] = county_mapping.get(user_profile['county'], -1) if user_profile['county'] else None\n",
    "\n",
    "# Veriyi ve kullanıcı profilini filtreleme\n",
    "filters = [\n",
    "    (df['price'] >= user_profile['min_price']) if user_profile['min_price'] is not None else pd.Series([True] * len(df)),\n",
    "    (df['price'] <= user_profile['max_price']) if user_profile['max_price'] is not None else pd.Series([True] * len(df)),\n",
    "    (df['rooms'] >= user_profile['min_rooms']) if user_profile['min_rooms'] is not None else pd.Series([True] * len(df)),\n",
    "    (df['rooms'] <= user_profile['max_rooms']) if user_profile['max_rooms'] is not None else pd.Series([True] * len(df)),\n",
    "    (df['build_year'] >= user_profile['min_build_year']) if user_profile['min_build_year'] is not None else pd.Series([True] * len(df)),\n",
    "    (df['build_year'] <= user_profile['max_build_year']) if user_profile['max_build_year'] is not None else pd.Series([True] * len(df)),\n",
    "    (df['balcony'] == user_profile['balcony']) if user_profile['balcony'] is not None else pd.Series([True] * len(df)),\n",
    "    (df['county'] == user_profile['county']) if user_profile['county'] is not None else pd.Series([True] * len(df)),\n",
    "    (df['property_type'] == user_profile['property_type']) if user_profile['property_type'] is not None else pd.Series([True] * len(df)),\n",
    "    (df['living_area'] >= user_profile['min_living_area']) if user_profile['min_living_area'] is not None else pd.Series([True] * len(df)),\n",
    "    (df['living_area'] <= user_profile['max_living_area']) if user_profile['max_living_area'] is not None else pd.Series([True] * len(df))\n",
    "]\n",
    "\n",
    "# Tüm filtreleri birleştirme\n",
    "combined_filters = filters[0]\n",
    "for filter_condition in filters[1:]:\n",
    "    combined_filters &= filter_condition\n",
    "\n",
    "filtered_df = df[combined_filters]\n",
    "\n",
    "# Ara sonuçları kontrol etmek için veri çerçevesinin başını yazdır\n",
    "print(filtered_df.head())"
   ],
   "id": "cd83facf519ad6da",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Filtrelenmiş veri olup olmadığını kontrol etme\n",
    "if filtered_df.empty:\n",
    "    print(\"Belirtilen kriterlere uygun ev bulunamadı.\")\n",
    "else:\n",
    "    # Filtrelenmiş veriyi ve kullanıcı profilini standartlaştırma\n",
    "    features = filtered_df[['price', 'rooms', 'build_year', 'county', 'balcony', 'living_area']]\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "    # Kullanıcı profilini standartlaştırma\n",
    "    user_profile_values = [\n",
    "        user_profile['max_price'] if user_profile['max_price'] is not None else df['price'].max(),\n",
    "        user_profile['max_rooms'] if user_profile['max_rooms'] is not None else df['rooms'].max(),\n",
    "        user_profile['max_build_year'] if user_profile['max_build_year'] is not None else df['build_year'].max(),\n",
    "        user_profile['county'] if user_profile['county'] is not None else -1,\n",
    "        user_profile['balcony'] if user_profile['balcony'] is not None else df['balcony'].mode()[0],\n",
    "        user_profile['max_living_area'] if user_profile['max_living_area'] is not None else df['living_area'].max()\n",
    "    ]\n",
    "\n",
    "    user_profile_scaled = scaler.transform([user_profile_values])\n",
    "\n",
    "    # Benzerlik hesaplama\n",
    "    similarities = cosine_similarity(user_profile_scaled, scaled_features)\n",
    "    filtered_df['similarity'] = similarities[0]\n",
    "\n",
    "    # Öneri listesi\n",
    "    recommendations = filtered_df.sort_values(by='similarity', ascending=False)\n",
    "    recommendations\n"
   ],
   "id": "671540b271af2d94",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e273de9567461be6",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "99dda25a7394cf4d",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"hemnet.csv\")\n",
    "# build_year sütununu yıl olarak parçalama\n",
    "df['build_year'] = pd.to_datetime(df['build_year']).dt.year\n",
    "df.head()"
   ],
   "id": "24a2e85f4df43023",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_user_input():\n",
    "    try:\n",
    "        price_min = float(input(\"Minimum fiyat (boş bırakabilirsiniz): \") or -float('inf'))\n",
    "    except ValueError:\n",
    "        price_min = -float('inf')\n",
    "    \n",
    "    try:\n",
    "        price_max = float(input(\"Maksimum fiyat (boş bırakabilirsiniz): \") or float('inf'))\n",
    "    except ValueError:\n",
    "        price_max = float('inf')\n",
    "\n",
    "    property_type = input(\"Mülk tipi (Apartment/House) (boş bırakabilirsiniz): \").strip() or None\n",
    "    try:\n",
    "        living_area_min = float(input(\"Minimum m2 (boş bırakabilirsiniz): \") or 0)\n",
    "    except ValueError:\n",
    "        living_area_min = 0\n",
    "\n",
    "    try:\n",
    "        living_area_max = float(input(\"Maksimum m2 (boş bırakabilirsiniz): \") or float('inf'))\n",
    "    except ValueError:\n",
    "        living_area_max = float('inf')\n",
    "\n",
    "    balcony = input(\"Balkon istiyor musunuz? (Evet/Hayır) (boş bırakabilirsiniz): \").strip() or None\n",
    "    city = input(\"Şehir (boş bırakabilirsiniz): \").strip() or None\n",
    "    \n",
    "    return price_min, price_max, property_type, living_area_min, living_area_max, balcony, city\n"
   ],
   "id": "e83701ffd63b7f55",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def filter_properties(df, price_min, price_max, property_type, living_area_min, living_area_max, balcony, city):\n",
    "    filtered_df = df[\n",
    "        (df['price'] >= price_min) &\n",
    "        (df['price'] <= price_max) &\n",
    "        (df['living_area'] >= living_area_min) &\n",
    "        (df['living_area'] <= living_area_max)\n",
    "    ]\n",
    "    \n",
    "    if property_type:\n",
    "        filtered_df = filtered_df[filtered_df['property_type'].str.contains(property_type, case=False)]\n",
    "    \n",
    "    if balcony == 'Evet':\n",
    "        filtered_df = filtered_df[filtered_df['balcony'] == 'Ja']\n",
    "    elif balcony == 'Hayır':\n",
    "        filtered_df = filtered_df[filtered_df['balcony'] != 'Ja']\n",
    "    \n",
    "    if city:\n",
    "        filtered_df = filtered_df[filtered_df['county'].str.contains(city, case=False)]\n",
    "    \n",
    "    return filtered_df\n",
    "\n",
    "# Kullanıcı girdilerini alma\n",
    "price_min, price_max, property_type, living_area_min, living_area_max, balcony, city = get_user_input()\n",
    "\n",
    "# Verileri filtreleme\n",
    "filtered_df = filter_properties(df, price_min, price_max, property_type, living_area_min, living_area_max, balcony, city)\n",
    "print(filtered_df)\n"
   ],
   "id": "4023d0cf29394e53",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Sonuçları CSV dosyasına kaydetme\n",
    "filtered_df.to_csv('filtered_properties.csv', index=False)\n",
    "\n",
    "print(\"Önerilen evler 'filtered_properties.csv' dosyasına kaydedildi.\")"
   ],
   "id": "e8b2c44fc17123f0",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import streamlit as st\n",
    "\n",
    "def filter_properties(df, price_min, price_max, property_type, living_area_min, living_area_max, balcony, city):\n",
    "    filtered_df = df[\n",
    "        (df['price'] >= price_min) &\n",
    "        (df['price'] <= price_max) &\n",
    "        (df['living_area'] >= living_area_min) &\n",
    "        (df['living_area'] <= living_area_max)\n",
    "    ]\n",
    "    \n",
    "    if property_type:\n",
    "        filtered_df = filtered_df[filtered_df['property_type'].str.contains(property_type, case=False)]\n",
    "    \n",
    "    if balcony == 'Evet':\n",
    "        filtered_df = filtered_df[filtered_df['balcony'] == 'Ja']\n",
    "    elif balcony == 'Hayır':\n",
    "        filtered_df = filtered_df[filtered_df['balcony'] != 'Ja']\n",
    "    \n",
    "    if city:\n",
    "        filtered_df = filtered_df[filtered_df['county'].str.contains(city, case=False)]\n",
    "    \n",
    "    return filtered_df\n",
    "\n",
    "# Streamlit uygulaması\n",
    "st.title(\"Ev Öneri Sistemi\")\n",
    "\n",
    "price_min = st.number_input(\"Minimum fiyat\", min_value=0.0, value=0.0, step=10000.0)\n",
    "price_max = st.number_input(\"Maksimum fiyat\", min_value=0.0, value=10000000.0, step=10000.0)\n",
    "property_type = st.selectbox(\"Mülk tipi\", [\"Apartment\", \"House\", \"Any\"], index=2)\n",
    "living_area_min = st.number_input(\"Minimum m2\", min_value=0.0, value=0.0, step=1.0)\n",
    "living_area_max = st.number_input(\"Maksimum m2\", min_value=0.0, value=1000.0, step=1.0)\n",
    "balcony = st.selectbox(\"Balkon istiyor musunuz?\", [\"Evet\", \"Hayır\", \"Farketmez\"], index=2)\n",
    "city = st.text_input(\"Şehir\")\n",
    "\n",
    "if st.button(\"Evleri Listele\"):\n",
    "    property_type = None if property_type == \"Any\" else property_type\n",
    "    balcony = None if balcony == \"Farketmez\" else balcony\n",
    "    filtered_df = filter_properties(df, price_min, price_max, property_type, living_area_min, living_area_max, balcony, city)\n",
    "    \n",
    "    st.write(\"Önerilen Evler:\")\n",
    "    st.write(filtered_df)\n",
    "    \n",
    "    csv = filtered_df.to_csv(index=False).encode('utf-8')\n",
    "    st.download_button(\n",
    "        label=\"Önerilen evleri CSV olarak indir\",\n",
    "        data=csv,\n",
    "        file_name='filtered_properties.csv',\n",
    "        mime='text/csv',\n",
    "    )"
   ],
   "id": "fd701892eaf41c62",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
